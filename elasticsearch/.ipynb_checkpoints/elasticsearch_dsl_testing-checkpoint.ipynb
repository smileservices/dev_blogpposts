{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "import elasticsearch_dsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "es = Elasticsearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc = {\n",
    "    'author': 'kimchy',\n",
    "    'text': 'Elasticsearch: cool. bonsai cool.',\n",
    "    'timestamp': datetime.now(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated\n",
      "{'text': 'Elasticsearch: cool. bonsai cool.', 'author': 'kimchy', 'timestamp': '2019-04-21T22:19:59.891847'}\n",
      "Got 4 Hits:\n",
      "2019-04-21T21:46:58.764720 borat: de veghe in cacat\n",
      "2019-04-21T21:46:58.764720 taranu: ce-ti mai place\n",
      "2019-04-21T21:46:58.764720 americanu: veghe in lan\n",
      "2019-04-21T22:19:59.891847 kimchy: Elasticsearch: cool. bonsai cool.\n"
     ]
    }
   ],
   "source": [
    "# add\n",
    "res = es.index(index=\"test-index\", doc_type='tweet', id=1, body=doc)\n",
    "print(res['result'])\n",
    "\n",
    "# get\n",
    "res = es.get(index=\"test-index\", doc_type='tweet', id=1)\n",
    "print(res['_source'])\n",
    "\n",
    "# refresh\n",
    "es.indices.refresh(index=\"test-index\")\n",
    "\n",
    "# query\n",
    "res = es.search(index=\"test-index\", body={\"query\": {\"match_all\": {}}})\n",
    "print(\"Got %d Hits:\" % res['hits']['total']['value'])\n",
    "for hit in res['hits']['hits']:\n",
    "    print(\"%(timestamp)s %(author)s: %(text)s\" % hit[\"_source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created\n",
      "created\n",
      "created\n",
      "created\n"
     ]
    }
   ],
   "source": [
    "bulk_list = [\n",
    "    {\n",
    "    'author': 'kimchy',\n",
    "    'text': 'Elasticsearch: cool. bonsai cool.',\n",
    "    'timestamp': datetime.now(),\n",
    "    },\n",
    "    {\n",
    "    'author': 'borat',\n",
    "    'text': 'de veghe in cacat',\n",
    "    'timestamp': datetime.now(),\n",
    "    },\n",
    "    {\n",
    "    'author': 'taranu',\n",
    "    'text': 'ce-ti mai place',\n",
    "    'timestamp': datetime.now(),\n",
    "    },\n",
    "    {\n",
    "    'author': 'americanu',\n",
    "    'text': 'veghe in lan',\n",
    "    'timestamp': datetime.now(),\n",
    "    },\n",
    "]\n",
    "\n",
    "for idx, b in enumerate(bulk_list):\n",
    "    res = es.index(index=\"second_index\", doc_type='book', id=idx+1, body=b)\n",
    "    print(res['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_shards': {'failed': 0, 'successful': 1, 'total': 2}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.indices.refresh(index=\"second_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using elasticsearch-dsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build a DSL Search object on the 'commits' index, 'summary' document type\n",
    "request = elasticsearch_dsl.Search(using=es, index='second_index',\n",
    "                                    doc_type='book')\n",
    "\n",
    "# Restrict to only some fields\n",
    "request = request.source(['text', 'author'])\n",
    "\n",
    "# Run the Search, using the scan interface to get all resuls\n",
    "response = request.scan()\n",
    "dd = []\n",
    "for commit in response:\n",
    "    dd.append(commit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = elasticsearch_dsl.Search(using=es, index='second_index',\n",
    "                                    doc_type='book')\n",
    "# 1\n",
    "s1 = s.query('match', text='veghe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response: [<Hit(second_index/book/4): {'text': 'veghe in lan', 'author': 'americanu', 'timestamp':...}>, <Hit(second_index/book/2): {'text': 'de veghe in cacat', 'author': 'borat', 'timestamp'...}>]>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 2\n",
    "from elasticsearch_dsl.query import MultiMatch, Match, Fuzzy\n",
    "\n",
    "# {\"multi_match\": {\"query\": \"python django\", \"fields\": [\"title\", \"body\"]}}\n",
    "mm = MultiMatch(query='americanu', fields=['text', 'author'])\n",
    "\n",
    "# {\"match\": {\"title\": {\"query\": \"web framework\", \"type\": \"phrase\"}}}\n",
    "m = Match(text={\"query\": \"veghe\"})\n",
    "\n",
    "s21 = s.query(mm)\n",
    "s22 = s.query(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response: [<Hit(second_index/book/4): {'text': 'veghe in lan', 'author': 'americanu', 'timestamp':...}>]>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s21.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response: [<Hit(second_index/book/4): {'text': 'veghe in lan', 'author': 'americanu', 'timestamp':...}>, <Hit(second_index/book/2): {'text': 'de veghe in cacat', 'author': 'borat', 'timestamp'...}>]>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s22.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Making fuzzy queries only using -dsl library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from elasticsearch_dsl import Index, Document, Text, Integer, Completion, analyzer, tokenizer, connections\n",
    "\n",
    "skills = [\n",
    "    {'name': 'python'},\n",
    "    {'name': 'c++'},\n",
    "    {'name': 'pycharm'},\n",
    "    {'name': 'php'},\n",
    "    {'name': 'curl'},\n",
    "    {'name': 'pyglass'},\n",
    "    {'name': 'pig farm'},\n",
    "]\n",
    "\n",
    "my_analyzer = analyzer('my_analyzer',\n",
    "    tokenizer=tokenizer('trigram', 'edge_ngram', min_gram=1, max_gram=20),\n",
    "    filter=['lowercase']\n",
    ")\n",
    "\n",
    "class SkillDoc(Document):\n",
    "  name = Text(\n",
    "    analyzer=my_analyzer\n",
    "  )\n",
    "  id = Integer()\n",
    "\n",
    "  class Index:\n",
    "    name = 'skills'\n",
    "    \n",
    "connections.create_connection(hosts=['localhost:9200'], timeout=20)\n",
    "\n",
    "for i, skill in enumerate(skills):\n",
    "    sk = SkillDoc(\n",
    "        name=skill['name'],\n",
    "        id = i,\n",
    "        meta = {'id':i},\n",
    "    )\n",
    "    sk.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skills_index = Index('skills')\n",
    "skills_index.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5 (crawling)",
   "language": "python",
   "name": "crawling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
